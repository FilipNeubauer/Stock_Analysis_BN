Bayesian Network:
    nodes: change_discretize30, SMA_7_discretize, rsi_discretize
    every node equally discretized
    estimator: MaximumLikelihoodEstimator
    (mostly predicting up)
    AAPL: 
        Performance:  0.6046114432109309
        Accuracy Positives:  0.605424321959755
        Accuracy Negatives:  0.5714285714285714
    IBM:
        Performance:  0.5622866894197952
        Accuracy Positives:  0.5681581685744017
        Accuracy Negatives:  0.5355450236966824
    MSFT:
        Performance:  0.5981228668941979
        Accuracy Positives:  0.6079136690647482
        Accuracy Negatives:  0.4166666666666667

    
Logistic Reggression:
    inputs: change_shifted30, SMA_change7_shifted (continuous)
    solver: liblinear (default)
    (only predicting up)
    AAPL:
        Performance:  0.601195559350982
        Accuracy Positives:  0.601195559350982
        Accuracy Negatives:  no negatives predicted
    IBM:
        Performance:  0.5494880546075085
        Accuracy Positives:  0.5494880546075085
        Accuracy Negatives:  no negatives predicted
    MSFT:
        Performance:  0.606655290102389
        Accuracy Positives:  0.606655290102389
        Accuracy Negatives:  no negatives predicted

    class_weight = 'balanced'
    inputs: change_shifted30, SMA_change7_shifted (continuous)
    solver: liblinear (default)
    (only predicting up)
    AAPL:
        Performance:  0.5644748078565329
        Accuracy Positives:  0.6465256797583081
        Accuracy Negatives:  0.4577603143418468
    IBM:
        Performance:  0.5315699658703071
        Accuracy Positives:  0.5837742504409171
        Accuracy Negatives:  0.4826446280991736
    MSFT:
        Performance:  0.4863481228668942
        Accuracy Positives:  0.6230248306997742
        Accuracy Negatives:  0.40329218106995884

Naive Bayes text classifier:
    DJIA data
    SMOTE + Top 1-5, no lemm:
        Performance:  0.5050251256281407
        Accuracy Positives:  0.5126903553299492
        Accuracy Negatives:  0.4975124378109453
    SMOTE + Top 1-25, no lemm:
        Performance:  0.5150753768844221
        Accuracy Positives:  0.5177865612648221
        Accuracy Negatives:  0.5103448275862069
    *SMOTE + Top 1-25, test size 0.2, shuffle=False:
        Performance:  0.5276381909547738
        Accuracy Positives:  0.5301724137931034
        Accuracy Negatives:  0.5240963855421686
    SMOTE + Top 1-25, test size 0.2, shuffle=True:
        Performance:  0.5175879396984925
        Accuracy Positives:  0.5914893617021276
        Accuracy Negatives:  0.4110429447852761
    SMOTE, random_state=42:
        Performance:  0.49246231155778897
        Accuracy Positives:  0.5598086124401914
        Accuracy Negatives:  0.41798941798941797


    Random oversampling + Top 1-25, test size 0.2:
        Performance:  0.4949748743718593
        Accuracy Positives:  0.5018315018315018
        Accuracy Negatives:  0.48
    *Random oversampling, shuffle=True:
        Performance:  0.5226130653266332
        Accuracy Positives:  0.5116279069767442
        Accuracy Negatives:  0.5355191256830601
    Random oversampling, random_state=42:
        Performance:  0.507537688442211
        Accuracy Positives:  0.5676855895196506
        Accuracy Negatives:  0.4260355029585799


Naive Bayes text calssifier after consultation:
    lemm, removing punctuation, stopwords
    only CountVectorizer:
        Performance:  0.4899497487437186
        Accuracy Positives:  0.5504201680672269
        Accuracy Negatives:  0.4

    alpha=0.1:
                            Actual up  Actual Down
        Predicted up          120           90
        Predicted down        107           81
        Performance:  0.5050251256281407
        Accuracy Positives:  0.5714285714285714
        Accuracy Negatives:  0.4308510638297872

    without one_words + alpha=0.1:
                            Actual up  Actual Down
        Predicted up          122           93
        Predicted down        105           78
        Performance:  0.5025125628140703
        Accuracy Positives:  0.5674418604651162
        Accuracy Negatives:  0.4262295081967213

    alpha=0.1 + without my_own_words:
        Predicted up          121           90
        Predicted down        106           81
        Performance:  0.507537688442211
        Accuracy Positives:  0.5734597156398105
        Accuracy Negatives:  0.43315508021390375

    alpha=0.1 + shuffle=False:
                        Actual up  Actual Down
        Predicted up          126          110
        Predicted down         76           86
        Performance:  0.5326633165829145
        Accuracy Positives:  0.5338983050847458
        Accuracy Negatives:  0.5308641975308642
    
    external preprocessing, shuffle=False, alpha=0.1:
                        Actual up  Actual Down
        Predicted up          122          104
        Predicted down         80           92
        Performance:  0.5376884422110553
        Accuracy Positives:  0.5398230088495575
        Accuracy Negatives:  0.5348837209302325

    




----------------------------------------------------------------
AAPL:
    up      3349
    down    2505
IBM:
    up      3132
    down    2728
MSFT:
    up      3199
    down    2661
    


TO DO:
    LSTM
    word classification
    Bayesian logistic regression???


(1989, 47598)