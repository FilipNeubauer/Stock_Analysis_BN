{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63d898d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import inflect\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89a94d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "\n",
    "\n",
    "# modified stop words so that they are without punctuation\n",
    "def create_my_stop_words():\n",
    "    my_stop_words = []       # stop words without punctuation\n",
    "    for word in stopwords.words(\"english\"): \n",
    "        my_word = \"\"\n",
    "        for char in word:\n",
    "            if char not in string.punctuation:\n",
    "                my_word += char\n",
    "        my_stop_words.append(my_word)\n",
    "\n",
    "    other_not_included = [\"hed\", \"itd\", \"theyd\", \"youd\", \"me\"] # shed, wed, id are common words but he had, it had, they had, you had\n",
    "    for word in other_not_included:\n",
    "        my_stop_words.append(word)\n",
    "    return my_stop_words\n",
    "\n",
    "\n",
    "# plural word -> singular word\n",
    "def singularize_word(word):\n",
    "    p = inflect.engine()\n",
    "    singular_word = p.singular_noun(word)\n",
    "    if singular_word:\n",
    "        return singular_word\n",
    "    else:\n",
    "        return word\n",
    "    \n",
    "\n",
    "# prepare dataset\n",
    "def prepare_kaggle_dataset(df):\n",
    "    df.fillna(\"\", inplace=True) # filling empty fields\n",
    "    df[\"combined\"] = df[['Top1', \"Top2\", \"Top3\", 'Top4', 'Top5', 'Top6', 'Top7',\n",
    "      'Top8', 'Top9', 'Top10', 'Top11', 'Top12', 'Top13', 'Top14', 'Top15',\n",
    "      'Top16', 'Top17', 'Top18', 'Top19', 'Top20', 'Top21', 'Top22', 'Top23',\n",
    "       'Top24', 'Top25']].apply(lambda row: \" \".join(row), axis=1) # combining all columns into one\n",
    "    \n",
    "    new_df = pd.DataFrame(data={\"combined\": df[\"combined\"], \"label\": df[\"Label\"]})\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "\n",
    "#test = 0\n",
    "\n",
    "# text cleaning \n",
    "def text_cleanning(row):\n",
    "    global test\n",
    "    remove_b = row.replace(\"b\\\"\", \"\").replace(\"b'\", \"\")   # removing b\" and b'\n",
    "    remove_punc = \"\".join([char for char in remove_b if char not in string.punctuation])     # removing punctuation !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
    "    remove_stop_words = [word for word in remove_punc.split() if word.lower() not in my_stop_words]  # removing stopwords\n",
    "    \n",
    "\n",
    "\n",
    "    # comparing different techniques for removing suffixis\n",
    "    \"\"\"\n",
    "    for i in remove_stop_words:\n",
    "        print(i, \" : \", porter_stemmer.stem(i, to_lowercase=False), \" : \", lemmatizer.lemmatize(i), \" : \", singularize_word(i))\n",
    "    \"\"\"\n",
    "    \n",
    "    lem_words = [lemmatizer.lemmatize(word) for word in remove_stop_words] # base of the words\n",
    "\n",
    "    singular_words = [singularize_word(word) for word in lem_words]         # plural -> singular\n",
    "    #if \"me\" in singular_words or \"Me\" in singular_words:\n",
    "     #   test += 1\n",
    "\n",
    "    return \" \".join(singular_words)  # returning cleaned row as a string\n",
    "\n",
    "\n",
    "# get each word in Count Vectorizer with its count in 0, 1 and total\n",
    "def get_word_counts():\n",
    "    feature_names = tokenizer.get_feature_names_out()\n",
    "\n",
    "    # Get the indices of the \"0\" and \"1\" texts in the DataFrame\n",
    "    indices_0 = df[df[\"label\"] == 0].index\n",
    "    indices_1 = df[df[\"label\"] == 1].index\n",
    "\n",
    "    # Get the occurrences of each word in the \"0\" texts\n",
    "    word_counts_0 = tokenized_words[indices_0].sum(axis=0)\n",
    "\n",
    "    # Get the occurrences of each word in the \"1\" texts\n",
    "    word_counts_1 = tokenized_words[indices_1].sum(axis=0)\n",
    "\n",
    "    # Create a dictionary to store the word counts\n",
    "    word_counts = {\n",
    "        \"word\": feature_names,\n",
    "        \"count_0\": word_counts_0.tolist()[0],\n",
    "        \"count_1\": word_counts_1.tolist()[0],\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Create a DataFrame from the word counts dictionary\n",
    "    word_counts_df = pd.DataFrame(word_counts)\n",
    "    word_counts_df[\"count\"] = word_counts_df[\"count_0\"] + word_counts_df[\"count_1\"]\n",
    "\n",
    "    return word_counts_df\n",
    "\n",
    "\n",
    "# printing the prob table\n",
    "def print_probabilities():\n",
    "    feature_log_probs = model.feature_log_prob_\n",
    "\n",
    "    # Convert feature log probabilities to probabilities\n",
    "    feature_probs = np.exp(feature_log_probs)\n",
    "\n",
    "    sorted_vocabulary = sorted(tokenizer.vocabulary_.items(), key=lambda x: x[1])\n",
    "\n",
    "    vocab_arr = [item[0] for item in sorted_vocabulary]\n",
    "\n",
    "    # Create a DataFrame to represent the probabilistic table\n",
    "    prob_table = pd.DataFrame(feature_probs, columns=vocab_arr)\n",
    "\n",
    "    word_counts_df = get_word_counts()  # getting the counts\n",
    "    word_counts_df.set_index(\"word\", inplace=True)  # making the word column index so it will match the prob_table\n",
    "    \n",
    "    prob_table = prob_table.transpose().sort_index()\n",
    "    prob_table[\"count\"] = word_counts_df[\"count\"]\n",
    "    prob_table[\"count_0\"] = word_counts_df[\"count_0\"]\n",
    "    prob_table[\"count_1\"] = word_counts_df[\"count_1\"]\n",
    "    \n",
    "    \n",
    "    #for_csv = prob_table.reset_index()   # adding indexes back\n",
    "    #for_csv.to_csv(\"words_for_analysis.csv\")\n",
    "    \n",
    "    # probability ratio\n",
    "    prob_table[\"prob_ratio\"] =  prob_table.iloc[:,1] / prob_table.iloc[:, 0]\n",
    "    \n",
    "    # product of prob_ratio and count\n",
    "    prob_table[\"product_ratio_count\"] = prob_table[\"count\"] * prob_table[\"prob_ratio\"]\n",
    "\n",
    "    # priting the dataframe to a txt file\n",
    "    with open(\"output.txt\", \"w\") as f:\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.width', None)\n",
    "        pd.set_option('display.expand_frame_repr', False)\n",
    "        #pd.set_option('display.max_colwidth', -1) \n",
    "\n",
    "        #print(prob_table.sort_values(\"pomer\",  ascending=False), file=f) # sort by biggest impact on 0\n",
    "        print(prob_table.sort_values(\"product_ratio_count\", ascending=False), file=f)\n",
    "        \n",
    "\n",
    "        pd.reset_option('all')\n",
    "        \n",
    "\n",
    "# checking the performance\n",
    "def my_confusion_matrix(data, predicted_col, true_col, up=\"up\", down=\"down\"):\n",
    "    tp = data.loc[(data[predicted_col] == up) & (data[true_col] == up)]\n",
    "    fp = data.loc[(data[predicted_col] == up) & (data[true_col] == down)]\n",
    "    fn = data.loc[(data[predicted_col] == down) & (data[true_col] == up)]\n",
    "    tn = data.loc[(data[predicted_col] == down) & (data[true_col] == down)]\n",
    "\n",
    "    df = pd.DataFrame({\"Actual up\":[len(tp), len(fn)], \"Actual Down\":[len(fp), len(tn)]}, index=[\"Predicted up\", \"Predicted down\"])\n",
    "\n",
    "    performance = (len(tp) + len(tn)) / (len(tp) + len(tn) + len(fp) + len(fn))\n",
    "    accuracyP = (len(tp) / (len(tp) + len(fp)))\n",
    "    \n",
    "    balance = 0.5*( (len(tp)/(len(tp)+len(fn))) + (len(tn)/(len(tn) + len(fp))))\n",
    "    \n",
    "\n",
    "    if (len(tn) + len(fn)) == 0:\n",
    "        accuracyN = \"no negatives predicted\"\n",
    "    else:\n",
    "        accuracyN = (len(tn) / (len(tn) + len(fn)))\n",
    "        \n",
    "    return [balance, len(tp), len(fp), len(fn), len(tn)]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99214dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "my_stop_words = create_my_stop_words()\n",
    "\n",
    "# load kaggle data\n",
    "df = pd.read_csv(\"Combined_News_DJIA.csv\")\n",
    "df = prepare_kaggle_dataset(df)\n",
    "\n",
    "# load news category data\n",
    "#df_2 = pd.read_csv(\"news_category_data.csv\")\n",
    "\n",
    "# concatenate\n",
    "#df = pd.concat([df, df_2], ignore_index=True)\n",
    "\n",
    "\n",
    "# testing\n",
    "#df = df.head(100)\n",
    "\n",
    "df[\"combined\"] = df['combined'].apply(text_cleanning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3a44a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 0.5591247672253259\n",
      "min_df: 24\n",
      "min_samples_leaf: 7\n",
      "max_depth: 13\n",
      "[0.5025226278636699, 193, 133, 65, 46]\n",
      "\n",
      "Validation: 0.5599800788185874\n",
      "min_df: 25\n",
      "min_samples_leaf: 6\n",
      "max_depth: 13\n",
      "[0.4977913472781603, 192, 134, 66, 45]\n",
      "\n",
      "Validation: 0.529372915854662\n",
      "min_df: 26\n",
      "min_samples_leaf: 4\n",
      "max_depth: 14\n",
      "[0.5038326620761335, 198, 136, 60, 43]\n",
      "\n",
      "Validation: 0.5341041964401715\n",
      "min_df: 27\n",
      "min_samples_leaf: 4\n",
      "max_depth: 14\n",
      "[0.506625958165519, 198, 135, 60, 44]\n",
      "\n",
      "Validation: 0.5265796197652766\n",
      "min_df: 28\n",
      "min_samples_leaf: 7\n",
      "max_depth: 13\n",
      "[0.5063985968559179, 195, 133, 63, 46]\n",
      "\n",
      "Validation: 0.5276622926681391\n",
      "min_df: 29\n",
      "min_samples_leaf: 4\n",
      "max_depth: 12\n",
      "[0.5143778961500152, 202, 135, 56, 44]\n",
      "\n",
      "Validation: 0.5265796197652766\n",
      "min_df: 30\n",
      "min_samples_leaf: 4\n",
      "max_depth: 12\n",
      "[0.5160885193365381, 200, 133, 58, 46]\n",
      "\n",
      "Validation: 0.5268069810748777\n",
      "min_df: 31\n",
      "min_samples_leaf: 6\n",
      "max_depth: 12\n",
      "[0.5115846000606297, 202, 136, 56, 43]\n",
      "\n",
      "Validation: 0.5257243081720151\n",
      "min_df: 32\n",
      "min_samples_leaf: 4\n",
      "max_depth: 12\n",
      "[0.5171711922394007, 202, 134, 56, 45]\n",
      "\n",
      "Validation: 0.5285176042614006\n",
      "min_df: 33\n",
      "min_samples_leaf: 4\n",
      "max_depth: 12\n",
      "[0.5126672729634922, 204, 137, 54, 42]\n",
      "\n",
      "Validation: 0.5276622926681391\n",
      "min_df: 34\n",
      "min_samples_leaf: 7\n",
      "max_depth: 12\n",
      "[0.5096466155645056, 201, 136, 57, 43]\n",
      "\n",
      "Validation: 0.5347862803689749\n",
      "min_df: 35\n",
      "min_samples_leaf: 2\n",
      "max_depth: 14\n",
      "[0.4945433285695725, 186, 131, 72, 48]\n",
      "\n",
      "Validation: 0.5319929842795894\n",
      "min_df: 36\n",
      "min_samples_leaf: 6\n",
      "max_depth: 14\n",
      "[0.5072539084491794, 194, 132, 64, 47]\n",
      "\n",
      "Validation: 0.5321662119440475\n",
      "min_df: 37\n",
      "min_samples_leaf: 4\n",
      "max_depth: 10\n",
      "[0.5078818587328396, 190, 129, 68, 50]\n",
      "\n",
      "Validation: 0.537070720194015\n",
      "min_df: 38\n",
      "min_samples_leaf: 7\n",
      "max_depth: 12\n",
      "[0.4869646182495344, 172, 124, 86, 55]\n",
      "\n",
      "Validation: 0.538662249361223\n",
      "min_df: 39\n",
      "min_samples_leaf: 6\n",
      "max_depth: 14\n",
      "[0.5242410462950933, 197, 128, 61, 51]\n",
      "\n",
      "Validation: 0.537070720194015\n",
      "min_df: 40\n",
      "min_samples_leaf: 7\n",
      "max_depth: 12\n",
      "[0.48417132216014896, 172, 125, 86, 54]\n",
      "\n",
      "Validation: 0.5392901996448833\n",
      "min_df: 41\n",
      "min_samples_leaf: 1\n",
      "max_depth: 14\n",
      "[0.510675154822225, 190, 128, 68, 51]\n",
      "\n",
      "Validation: 0.5375795764583604\n",
      "min_df: 42\n",
      "min_samples_leaf: 4\n",
      "max_depth: 14\n",
      "[0.5109025161318262, 193, 130, 65, 49]\n",
      "\n",
      "Validation: 0.542538218353471\n",
      "min_df: 43\n",
      "min_samples_leaf: 3\n",
      "max_depth: 14\n",
      "[0.5111298774414275, 196, 132, 62, 47]\n",
      "\n",
      "Validation: 0.5485253995063012\n",
      "min_df: 44\n",
      "min_samples_leaf: 4\n",
      "max_depth: 14\n",
      "[0.535186869343034, 194, 122, 64, 57]\n",
      "\n",
      "Validation: 0.5513186955956866\n",
      "min_df: 45\n",
      "min_samples_leaf: 4\n",
      "max_depth: 14\n",
      "[0.535186869343034, 194, 122, 64, 57]\n",
      "\n",
      "Validation: 0.5461326923909748\n",
      "min_df: 46\n",
      "min_samples_leaf: 4\n",
      "max_depth: 10\n",
      "[0.500985232341605, 185, 128, 73, 51]\n",
      "\n",
      "Validation: 0.5509181066216274\n",
      "min_df: 47\n",
      "min_samples_leaf: 2\n",
      "max_depth: 13\n",
      "[0.5014399549608073, 191, 132, 67, 47]\n",
      "\n",
      "Validation: 0.5487527608159023\n",
      "min_df: 48\n",
      "min_samples_leaf: 1\n",
      "max_depth: 14\n",
      "[0.5020679052444675, 187, 129, 71, 50]\n",
      "\n",
      "Validation: 0.5549673032783335\n",
      "min_df: 49\n",
      "min_samples_leaf: 4\n",
      "max_depth: 12\n",
      "[0.485936078991815, 183, 132, 75, 47]\n",
      "\n",
      "Validation: 0.5524013684985493\n",
      "min_df: 50\n",
      "min_samples_leaf: 6\n",
      "max_depth: 13\n",
      "[0.4941427395955134, 193, 136, 65, 43]\n",
      "\n",
      "Validation: 0.5620912909791693\n",
      "min_df: 51\n",
      "min_samples_leaf: 2\n",
      "max_depth: 14\n",
      "[0.4947706898791737, 189, 133, 69, 46]\n",
      "\n",
      "Validation: 0.5554220258975358\n",
      "min_df: 52\n",
      "min_samples_leaf: 1\n",
      "max_depth: 13\n",
      "[0.49608072409163745, 194, 136, 64, 43]\n",
      "\n",
      "Validation: 0.5640292754752934\n",
      "min_df: 53\n",
      "min_samples_leaf: 1\n",
      "max_depth: 14\n",
      "[0.49089472088692565, 187, 133, 71, 46]\n",
      "\n",
      "Validation: 0.5532566800918106\n",
      "min_df: 54\n",
      "min_samples_leaf: 2\n",
      "max_depth: 12\n",
      "[0.512385778008748, 188, 126, 70, 53]\n",
      "\n",
      "Validation: 0.5504633840024252\n",
      "min_df: 55\n",
      "min_samples_leaf: 3\n",
      "max_depth: 13\n",
      "[0.49972933177428436, 193, 134, 65, 45]\n",
      "\n",
      "Validation: 0.552174007188948\n",
      "min_df: 56\n",
      "min_samples_leaf: 2\n",
      "max_depth: 11\n",
      "[0.514323762504872, 189, 126, 69, 53]\n",
      "\n",
      "Validation: 0.5549673032783335\n",
      "min_df: 57\n",
      "min_samples_leaf: 1\n",
      "max_depth: 13\n",
      "[0.5033779394569313, 192, 132, 66, 47]\n",
      "\n",
      "Validation: 0.5493807110995625\n",
      "min_df: 58\n",
      "min_samples_leaf: 6\n",
      "max_depth: 12\n",
      "[0.4958533627820363, 191, 134, 67, 45]\n",
      "\n",
      "Validation: 0.5635745528560911\n",
      "min_df: 59\n",
      "min_samples_leaf: 2\n",
      "max_depth: 12\n",
      "[0.5113031051058854, 186, 125, 72, 54]\n",
      "\n",
      "Validation: 0.5534840414014117\n",
      "min_df: 60\n",
      "min_samples_leaf: 7\n",
      "max_depth: 13\n",
      "[0.5360421809362955, 193, 121, 65, 58]\n",
      "\n",
      "Validation: 0.5569052877744576\n",
      "min_df: 61\n",
      "min_samples_leaf: 8\n",
      "max_depth: 13\n",
      "[0.5252695855528128, 186, 120, 72, 59]\n",
      "\n",
      "Validation: 0.5571326490840587\n",
      "min_df: 62\n",
      "min_samples_leaf: 8\n",
      "max_depth: 13\n",
      "[0.5300008661383222, 187, 119, 71, 60]\n",
      "\n",
      "Validation: 0.5575332380581179\n",
      "min_df: 63\n",
      "min_samples_leaf: 8\n",
      "max_depth: 12\n",
      "[0.5372980815036161, 185, 115, 73, 64]\n",
      "\n",
      "Validation: 0.5498354337187649\n",
      "min_df: 64\n",
      "min_samples_leaf: 7\n",
      "max_depth: 13\n",
      "[0.5134684509116105, 190, 127, 68, 52]\n",
      "\n",
      "Validation: 0.5571326490840587\n",
      "min_df: 65\n",
      "min_samples_leaf: 7\n",
      "max_depth: 13\n",
      "[0.5276622926681391, 193, 124, 65, 55]\n",
      "\n",
      "Validation: 0.5571326490840587\n",
      "min_df: 66\n",
      "min_samples_leaf: 7\n",
      "max_depth: 13\n",
      "[0.5304555887575246, 193, 123, 65, 56]\n",
      "\n",
      "Validation: 0.5545125806591312\n",
      "min_df: 67\n",
      "min_samples_leaf: 7\n",
      "max_depth: 11\n",
      "[0.529372915854662, 191, 122, 67, 57]\n",
      "\n",
      "Validation: 0.5678511108223984\n",
      "min_df: 68\n",
      "min_samples_leaf: 7\n",
      "max_depth: 14\n",
      "[0.5104477935126239, 187, 126, 71, 53]\n",
      "\n",
      "Validation: 0.5635745528560911\n",
      "min_df: 69\n",
      "min_samples_leaf: 1\n",
      "max_depth: 14\n",
      "[0.4900394092936642, 188, 134, 70, 45]\n",
      "\n",
      "Validation: 0.5674505218483392\n",
      "min_df: 70\n",
      "min_samples_leaf: 5\n",
      "max_depth: 14\n",
      "[0.4984192975618206, 188, 131, 70, 48]\n",
      "\n",
      "Validation: 0.5618639296695682\n",
      "min_df: 71\n",
      "min_samples_leaf: 7\n",
      "max_depth: 13\n",
      "[0.5109025161318262, 193, 130, 65, 49]\n",
      "\n",
      "Validation: 0.5612359793859079\n",
      "min_df: 72\n",
      "min_samples_leaf: 4\n",
      "max_depth: 13\n",
      "[0.5022952665540686, 190, 131, 68, 48]\n",
      "\n",
      "Validation: 0.5493807110995625\n",
      "min_df: 73\n",
      "min_samples_leaf: 9\n",
      "max_depth: 9\n",
      "[0.5190550430903815, 190, 125, 68, 54]\n",
      "\n",
      "Validation: 0.5549673032783335\n",
      "min_df: 74\n",
      "min_samples_leaf: 9\n",
      "max_depth: 9\n",
      "[0.521848339179767, 190, 124, 68, 55]\n",
      "\n",
      "Validation: 0.5424840847083279\n",
      "min_df: 75\n",
      "min_samples_leaf: 9\n",
      "max_depth: 12\n",
      "[0.5259516694816162, 195, 126, 63, 53]\n",
      "\n",
      "Validation: 0.5375795764583604\n",
      "min_df: 76\n",
      "min_samples_leaf: 8\n",
      "max_depth: 6\n",
      "[0.5184270928067212, 194, 128, 64, 51]\n",
      "\n",
      "Validation: 0.535013641678576\n",
      "min_df: 77\n",
      "min_samples_leaf: 8\n",
      "max_depth: 7\n",
      "[0.523613096011433, 201, 131, 57, 48]\n",
      "\n",
      "Validation: 0.5345589190593738\n",
      "min_df: 78\n",
      "min_samples_leaf: 8\n",
      "max_depth: 6\n",
      "[0.5203650773028452, 195, 128, 63, 51]\n",
      "\n",
      "Validation: 0.5358689532718375\n",
      "min_df: 79\n",
      "min_samples_leaf: 9\n",
      "max_depth: 7\n",
      "[0.5152332077432766, 201, 134, 57, 45]\n",
      "\n",
      "Validation: 0.5422567233987268\n",
      "min_df: 80\n",
      "min_samples_leaf: 9\n",
      "max_depth: 5\n",
      "[0.5054891516175133, 183, 125, 75, 54]\n",
      "\n",
      "Validation: 0.5358689532718375\n",
      "min_df: 81\n",
      "min_samples_leaf: 9\n",
      "max_depth: 7\n",
      "[0.5152332077432766, 201, 134, 57, 45]\n",
      "\n",
      "Validation: 0.5345589190593738\n",
      "min_df: 82\n",
      "min_samples_leaf: 8\n",
      "max_depth: 6\n",
      "[0.5203650773028452, 195, 128, 63, 51]\n",
      "\n",
      "Validation: 0.5347862803689749\n",
      "min_df: 83\n",
      "min_samples_leaf: 8\n",
      "max_depth: 8\n",
      "[0.5130678619375515, 197, 132, 61, 47]\n",
      "\n",
      "Validation: 0.5384348880516219\n",
      "min_df: 84\n",
      "min_samples_leaf: 8\n",
      "max_depth: 6\n",
      "[0.5231583733922307, 195, 127, 63, 52]\n",
      "\n",
      "Validation: 0.538662249361223\n",
      "min_df: 85\n",
      "min_samples_leaf: 8\n",
      "max_depth: 8\n",
      "[0.5158611580269369, 197, 131, 61, 48]\n",
      "\n",
      "Validation: 0.535013641678576\n",
      "min_df: 86\n",
      "min_samples_leaf: 8\n",
      "max_depth: 7\n",
      "[0.523613096011433, 201, 131, 57, 48]\n",
      "\n",
      "Validation: 0.5347862803689749\n",
      "min_df: 87\n",
      "min_samples_leaf: 8\n",
      "max_depth: 8\n",
      "[0.5130678619375515, 197, 132, 61, 47]\n",
      "\n",
      "Validation: 0.5338768351305703\n",
      "min_df: 88\n",
      "min_samples_leaf: 4\n",
      "max_depth: 4\n",
      "[0.5016131826252652, 181, 125, 77, 54]\n",
      "\n",
      "Validation: 0.5358148196266943\n",
      "min_df: 89\n",
      "min_samples_leaf: 6\n",
      "max_depth: 5\n",
      "[0.5054891516175133, 183, 125, 75, 54]\n",
      "\n",
      "Validation: 0.5397449222640855\n",
      "min_df: 90\n",
      "min_samples_leaf: 8\n",
      "max_depth: 7\n",
      "[0.523613096011433, 201, 131, 57, 48]\n",
      "\n",
      "Validation: 0.5403187389026027\n",
      "min_df: 91\n",
      "min_samples_leaf: 8\n",
      "max_depth: 5\n",
      "[0.5082824477068988, 183, 124, 75, 55]\n",
      "\n",
      "Validation: 0.5441947078948508\n",
      "min_df: 92\n",
      "min_samples_leaf: 8\n",
      "max_depth: 5\n",
      "[0.5110757437962843, 183, 123, 75, 56]\n",
      "\n",
      "Validation: 0.5358689532718375\n",
      "min_df: 93\n",
      "min_samples_leaf: 8\n",
      "max_depth: 7\n",
      "[0.5208197999220476, 201, 132, 57, 47]\n",
      "\n",
      "Validation: 0.5403187389026027\n",
      "min_df: 94\n",
      "min_samples_leaf: 8\n",
      "max_depth: 5\n",
      "[0.5082824477068988, 183, 124, 75, 55]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 0.5358148196266943\n",
      "min_df: 95\n",
      "min_samples_leaf: 6\n",
      "max_depth: 5\n",
      "[0.5054891516175133, 183, 125, 75, 54]\n",
      "\n",
      "Validation: 0.5339309687757134\n",
      "min_df: 96\n",
      "min_samples_leaf: 6\n",
      "max_depth: 13\n",
      "[0.4995019704646832, 190, 132, 68, 47]\n",
      "\n",
      "Validation: 0.5358148196266943\n",
      "min_df: 97\n",
      "min_samples_leaf: 6\n",
      "max_depth: 5\n",
      "[0.5054891516175133, 183, 125, 75, 54]\n",
      "\n",
      "Validation: 0.5390628383352821\n",
      "min_df: 98\n",
      "min_samples_leaf: 1\n",
      "max_depth: 14\n",
      "[0.48143215971590664, 185, 135, 73, 44]\n",
      "\n",
      "Validation: 0.5358148196266943\n",
      "min_df: 99\n",
      "min_samples_leaf: 6\n",
      "max_depth: 5\n",
      "[0.5054891516175133, 183, 125, 75, 54]\n",
      "\n",
      "Validation: 0.5343856913949158\n",
      "min_df: 100\n",
      "min_samples_leaf: 3\n",
      "max_depth: 9\n",
      "[0.5154605690528777, 204, 136, 54, 43]\n",
      "\n",
      "Validation: 0.5375795764583604\n",
      "min_df: 101\n",
      "min_samples_leaf: 8\n",
      "max_depth: 6\n",
      "[0.5184270928067212, 194, 128, 64, 51]\n",
      "\n",
      "Validation: 0.535186869343034\n",
      "min_df: 102\n",
      "min_samples_leaf: 3\n",
      "max_depth: 14\n",
      "[0.49648131306569654, 187, 131, 71, 48]\n",
      "\n",
      "Validation: 0.5338768351305703\n",
      "min_df: 103\n",
      "min_samples_leaf: 4\n",
      "max_depth: 4\n",
      "[0.5016131826252652, 181, 125, 77, 54]\n",
      "\n",
      "Validation: 0.5337036074661123\n",
      "min_df: 104\n",
      "min_samples_leaf: 1\n",
      "max_depth: 14\n",
      "[0.4915768048157291, 196, 139, 62, 40]\n",
      "\n",
      "Validation: 0.5384348880516219\n",
      "min_df: 105\n",
      "min_samples_leaf: 8\n",
      "max_depth: 6\n",
      "[0.5231583733922307, 195, 127, 63, 52]\n",
      "\n",
      "Validation: 0.5358689532718375\n",
      "min_df: 106\n",
      "min_samples_leaf: 9\n",
      "max_depth: 7\n",
      "[0.5152332077432766, 201, 134, 57, 45]\n",
      "\n",
      "Validation: 0.5378069377679615\n",
      "min_df: 107\n",
      "min_samples_leaf: 9\n",
      "max_depth: 7\n",
      "[0.5180265038326621, 201, 133, 57, 46]\n",
      "\n",
      "Validation: 0.5345589190593738\n",
      "min_df: 108\n",
      "min_samples_leaf: 1\n",
      "max_depth: 11\n",
      "[0.516261747000996, 190, 126, 68, 53]\n",
      "\n",
      "Validation: 0.5338768351305703\n",
      "min_df: 109\n",
      "min_samples_leaf: 4\n",
      "max_depth: 4\n",
      "[0.49881988653587983, 181, 126, 77, 53]\n",
      "\n",
      "Validation: 0.5422567233987268\n",
      "min_df: 110\n",
      "min_samples_leaf: 9\n",
      "max_depth: 5\n",
      "[0.5054891516175133, 183, 125, 75, 54]\n",
      "\n",
      "Validation: 0.5373522151487593\n",
      "min_df: 111\n",
      "min_samples_leaf: 1\n",
      "max_depth: 14\n",
      "[0.48422545580529214, 185, 134, 73, 45]\n",
      "\n",
      "Validation: 0.5338768351305703\n",
      "min_df: 112\n",
      "min_samples_leaf: 4\n",
      "max_depth: 4\n",
      "[0.5016131826252652, 181, 125, 77, 54]\n",
      "\n",
      "Validation: 0.5358148196266943\n",
      "min_df: 113\n",
      "min_samples_leaf: 6\n",
      "max_depth: 5\n",
      "[0.5054891516175133, 183, 125, 75, 54]\n",
      "\n",
      "Validation: 0.5422567233987268\n",
      "min_df: 114\n",
      "min_samples_leaf: 9\n",
      "max_depth: 5\n",
      "[0.5054891516175133, 183, 125, 75, 54]\n",
      "\n",
      "Validation: 0.5422567233987268\n",
      "min_df: 115\n",
      "min_samples_leaf: 9\n",
      "max_depth: 5\n",
      "[0.5054891516175133, 183, 125, 75, 54]\n",
      "\n",
      "Validation: 0.5422567233987268\n",
      "min_df: 116\n",
      "min_samples_leaf: 9\n",
      "max_depth: 5\n",
      "[0.5054891516175133, 183, 125, 75, 54]\n",
      "\n",
      "Validation: 0.5441947078948508\n",
      "min_df: 117\n",
      "min_samples_leaf: 8\n",
      "max_depth: 5\n",
      "[0.5110757437962843, 183, 123, 75, 56]\n",
      "\n",
      "Validation: 0.535013641678576\n",
      "min_df: 118\n",
      "min_samples_leaf: 8\n",
      "max_depth: 7\n",
      "[0.523613096011433, 201, 131, 57, 48]\n",
      "\n",
      "Validation: 0.5364969035554978\n",
      "min_df: 119\n",
      "min_samples_leaf: 9\n",
      "max_depth: 6\n",
      "[0.5175717812134598, 195, 129, 63, 50]\n",
      "\n",
      "Validation: 0.5343315577497727\n",
      "min_df: 120\n",
      "min_samples_leaf: 7\n",
      "max_depth: 14\n",
      "[0.49904724784548093, 184, 128, 74, 51]\n",
      "\n",
      "Validation: 0.5371248538391581\n",
      "min_df: 121\n",
      "min_samples_leaf: 7\n",
      "max_depth: 14\n",
      "[0.4971092633493569, 183, 128, 75, 51]\n",
      "\n",
      "Validation: 0.5422567233987268\n",
      "min_df: 122\n",
      "min_samples_leaf: 9\n",
      "max_depth: 5\n",
      "[0.5054891516175133, 183, 125, 75, 54]\n",
      "\n",
      "Validation: 0.535186869343034\n",
      "min_df: 123\n",
      "min_samples_leaf: 7\n",
      "max_depth: 14\n",
      "[0.49904724784548093, 184, 128, 74, 51]\n",
      "\n",
      "Validation: 0.535186869343034\n",
      "min_df: 124\n",
      "min_samples_leaf: 7\n",
      "max_depth: 14\n",
      "[0.49904724784548093, 184, 128, 74, 51]\n",
      "\n",
      "Validation: 0.5338768351305703\n",
      "min_df: 125\n",
      "min_samples_leaf: 4\n",
      "max_depth: 4\n",
      "[0.49881988653587983, 181, 126, 77, 53]\n",
      "\n",
      "Validation: 0.5343315577497727\n",
      "min_df: 126\n",
      "min_samples_leaf: 7\n",
      "max_depth: 14\n",
      "[0.4999025594387424, 183, 127, 75, 52]\n",
      "\n",
      "Validation: 0.534959508033433\n",
      "min_df: 127\n",
      "min_samples_leaf: 1\n",
      "max_depth: 5\n",
      "[0.5026958555281279, 183, 126, 75, 53]\n",
      "\n",
      "Validation: 0.5356415919622364\n",
      "min_df: 128\n",
      "min_samples_leaf: 9\n",
      "max_depth: 6\n",
      "[0.5128405006279503, 194, 130, 64, 49]\n",
      "\n",
      "Validation: 0.5441947078948508\n",
      "min_df: 129\n",
      "min_samples_leaf: 8\n",
      "max_depth: 5\n",
      "[0.5110757437962843, 183, 123, 75, 56]\n",
      "\n",
      "Validation: 0.5343315577497727\n",
      "min_df: 130\n",
      "min_samples_leaf: 7\n",
      "max_depth: 14\n",
      "[0.4999025594387424, 183, 127, 75, 52]\n",
      "\n",
      "[[0.5678511108223984, 68, 7, 14]]\n"
     ]
    }
   ],
   "source": [
    "def decision_tree_tuning(df):\n",
    "    # every cycle randomly splitted into 10 parts\n",
    "\n",
    "    all_results = []\n",
    "    \n",
    "    for min_df in range(24,131): # from 25 difference to 130\n",
    "\n",
    "        tokenizer = CountVectorizer(analyzer=\"word\", lowercase=False, min_df=min_df, ngram_range=(1, 1))\n",
    "        tokenized_words = tokenizer.fit_transform(df[\"combined\"])\n",
    "\n",
    "        # training, validation, testing\n",
    "        X_train, X_test, y_train, y_test = train_test_split(tokenized_words, df[\"label\"], test_size=0.2,shuffle=True, random_state=42)\n",
    "        X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, shuffle=True, random_state=42)\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for min_samples_leaf in range(1, 10): # to 85\n",
    "\n",
    "            for max_depth in range(1, 15): # no difference after 135\n",
    "                #print(X_train.shape, X_val.shape, X_test.shape)\n",
    "                model = DecisionTreeClassifier(random_state=42, max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
    "                model.fit(X_train, y_train)\n",
    "                predict = model.predict(X_val)\n",
    "\n",
    "                conf = pd.DataFrame({\"Predicted\": predict, \"Actual\":y_val})\n",
    "                balance = my_confusion_matrix(conf, \"Predicted\", \"Actual\", up=1, down=0)[0]\n",
    "                results.append([balance, min_samples_leaf, max_depth])\n",
    "\n",
    "        best_result = max(results, key=lambda sublist: sublist[0])\n",
    "\n",
    "        model = DecisionTreeClassifier(random_state=42, max_depth=best_result[2], min_samples_leaf=best_result[1])\n",
    "        model.fit(X_train, y_train)\n",
    "        predict = model.predict(X_test)\n",
    "        conf = pd.DataFrame({\"Predicted\": predict, \"Actual\":y_val})\n",
    "        print(\"Validation:\", best_result[0])\n",
    "        print(\"min_df:\", min_df)\n",
    "        print(\"min_samples_leaf:\", best_result[1])\n",
    "        print(\"max_depth:\", best_result[2])\n",
    "        print(my_confusion_matrix(conf, \"Predicted\", \"Actual\", up=1, down=0))\n",
    "        print()\n",
    "        \n",
    "        all_results.append([best_result[0], min_df, best_result[1], best_result[2]])\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "\n",
    "all_results = decision_tree_tuning(df)\n",
    "\n",
    "# Find the maximum element in the first column\n",
    "max_value = max(row[0] for row in all_results)\n",
    "\n",
    "# Find the subarray(s) with the maximum element in the first column\n",
    "max_subarrays = [row for row in all_results if row[0] == max_value]\n",
    "\n",
    "print(max_subarrays) # [[0.5678511108223984, 68, 7, 14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f309226c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 0.5125698324022346\n",
      "min_df: 24\n",
      "alpha: 0.4\n",
      "[0.5061279286302023, 130, 88, 128, 91]\n",
      "\n",
      "Validation: 0.505673206011\n",
      "min_df: 25\n",
      "alpha: 0.0\n",
      "[0.5033346325408168, 130, 89, 128, 90]\n",
      "\n",
      "Validation: 0.5153631284916201\n",
      "min_df: 26\n",
      "alpha: 0.18\n",
      "[0.5024793209475553, 131, 90, 127, 89]\n",
      "\n",
      "Validation: 0.5125698324022346\n",
      "min_df: 27\n",
      "alpha: 0.46\n",
      "[0.49278939846693515, 126, 90, 132, 89]\n",
      "\n",
      "Validation: 0.5117145208089732\n",
      "min_df: 28\n",
      "alpha: 0.4\n",
      "[0.4977480403620458, 130, 91, 128, 88]\n",
      "\n",
      "Validation: 0.5108592092157118\n",
      "min_df: 29\n",
      "alpha: 0.9400000000000001\n",
      "[0.49409943267939893, 131, 93, 127, 86]\n",
      "\n",
      "Validation: 0.5183837858906067\n",
      "min_df: 30\n",
      "alpha: 0.7000000000000001\n",
      "[0.4996860248581698, 131, 91, 127, 88]\n",
      "\n",
      "Validation: 0.5214044432895933\n",
      "min_df: 31\n",
      "alpha: 0.47000000000000003\n",
      "[0.5119418821185744, 133, 88, 125, 91]\n",
      "\n",
      "Validation: 0.5166731627040839\n",
      "min_df: 32\n",
      "alpha: 0.64\n",
      "[0.5035619938504179, 133, 91, 125, 88]\n",
      "\n",
      "Validation: 0.5177558356069465\n",
      "min_df: 33\n",
      "alpha: 0.5\n",
      "[0.4968927287687844, 131, 92, 127, 87]\n",
      "\n",
      "Validation: 0.518611147200208\n",
      "min_df: 34\n",
      "alpha: 0.8300000000000001\n",
      "[0.5044173054436794, 132, 90, 126, 89]\n",
      "\n",
      "Validation: 0.528301069680828\n",
      "min_df: 35\n",
      "alpha: 0.75\n",
      "[0.5072106015330649, 132, 89, 126, 90]\n",
      "\n",
      "Validation: 0.5141072279242995\n",
      "min_df: 36\n",
      "alpha: 0.77\n",
      "[0.5091485860291889, 133, 89, 125, 90]\n",
      "\n",
      "Validation: 0.514962539517561\n",
      "min_df: 37\n",
      "alpha: 0.45\n",
      "[0.5158178511108225, 135, 88, 123, 91]\n",
      "\n",
      "Validation: 0.5065826512494045\n",
      "min_df: 38\n",
      "alpha: 0.0\n",
      "[0.5177558356069465, 136, 88, 122, 91]\n",
      "\n",
      "Validation: 0.5087479970551296\n",
      "min_df: 39\n",
      "alpha: 0.61\n",
      "[0.518611147200208, 135, 87, 123, 92]\n",
      "\n",
      "Validation: 0.4984301242908492\n",
      "min_df: 40\n",
      "alpha: 0.96\n",
      "[0.5061279286302023, 130, 88, 128, 91]\n",
      "\n",
      "Validation: 0.5078926854618683\n",
      "min_df: 41\n",
      "alpha: 0.09\n",
      "[0.5155904898012212, 132, 86, 126, 93]\n",
      "\n",
      "Validation: 0.5164999350396258\n",
      "min_df: 42\n",
      "alpha: 0.56\n",
      "[0.5203217703867308, 133, 85, 125, 94]\n",
      "\n",
      "Validation: 0.5279004807067689\n",
      "min_df: 43\n",
      "alpha: 0.4\n",
      "[0.5147351782079599, 133, 87, 125, 92]\n",
      "\n",
      "Validation: 0.5341150231692001\n",
      "min_df: 44\n",
      "alpha: 0.0\n",
      "[0.5089212247195878, 130, 87, 128, 92]\n",
      "\n",
      "Validation: 0.5321770386730761\n",
      "min_df: 45\n",
      "alpha: 0.0\n",
      "[0.5069832402234637, 129, 87, 129, 92]\n",
      "\n",
      "Validation: 0.5341150231692001\n",
      "min_df: 46\n",
      "alpha: 0.0\n",
      "[0.5089212247195878, 130, 87, 128, 92]\n",
      "\n",
      "Validation: 0.5227144775020571\n",
      "min_df: 47\n",
      "alpha: 0.0\n",
      "[0.5134251439954961, 128, 84, 130, 95]\n",
      "\n",
      "Validation: 0.5255077735914425\n",
      "min_df: 48\n",
      "alpha: 0.0\n",
      "[0.5162184400848815, 128, 83, 130, 96]\n",
      "\n",
      "Validation: 0.5300116928673508\n",
      "min_df: 49\n",
      "alpha: 0.0\n",
      "[0.5220323935732536, 131, 83, 127, 96]\n",
      "\n",
      "Validation: 0.5347429734528604\n",
      "min_df: 50\n",
      "alpha: 0.0\n",
      "[0.5259083625655017, 133, 83, 125, 96]\n",
      "\n",
      "Validation: 0.5300116928673508\n",
      "min_df: 51\n",
      "alpha: 0.0\n",
      "[0.5259083625655017, 133, 83, 125, 96]\n",
      "\n",
      "Validation: 0.528301069680828\n",
      "min_df: 52\n",
      "alpha: 0.0\n",
      "[0.5259083625655017, 133, 83, 125, 96]\n",
      "\n",
      "Validation: 0.5293837425836906\n",
      "min_df: 53\n",
      "alpha: 0.0\n",
      "[0.5317223160538738, 136, 83, 122, 96]\n",
      "\n",
      "Validation: 0.5235697890953185\n",
      "min_df: 54\n",
      "alpha: 0.0\n",
      "[0.5280737083712269, 137, 85, 121, 94]\n",
      "\n",
      "Validation: 0.52442510068858\n",
      "min_df: 55\n",
      "alpha: 0.0\n",
      "[0.5241977393789788, 135, 85, 123, 94]\n",
      "\n",
      "Validation: 0.5158178511108225\n",
      "min_df: 56\n",
      "alpha: 0.34\n",
      "[0.5252804122818414, 137, 86, 121, 93]\n",
      "\n",
      "Validation: 0.5091485860291889\n",
      "min_df: 57\n",
      "alpha: 0.0\n",
      "[0.5222597548828548, 134, 85, 124, 94]\n",
      "\n",
      "Validation: 0.5119418821185744\n",
      "min_df: 58\n",
      "alpha: 0.2\n",
      "[0.5166731627040839, 134, 87, 124, 92]\n",
      "\n",
      "Validation: 0.5147351782079599\n",
      "min_df: 59\n",
      "alpha: 0.44\n",
      "[0.5158178511108225, 135, 88, 123, 91]\n",
      "\n",
      "Validation: 0.5166731627040839\n",
      "min_df: 60\n",
      "alpha: 0.44\n",
      "[0.5147351782079599, 133, 87, 125, 92]\n",
      "\n",
      "Validation: 0.5214044432895933\n",
      "min_df: 61\n",
      "alpha: 0.42\n",
      "[0.5127971937118359, 132, 87, 126, 92]\n",
      "\n",
      "Validation: 0.5155904898012212\n",
      "min_df: 62\n",
      "alpha: 0.48\n",
      "[0.5119418821185744, 133, 88, 125, 91]\n",
      "\n",
      "Validation: 0.5203217703867308\n",
      "min_df: 63\n",
      "alpha: 0.2\n",
      "[0.5108592092157118, 131, 87, 127, 92]\n",
      "\n",
      "Validation: 0.5231150664761163\n",
      "min_df: 64\n",
      "alpha: 0.42\n",
      "[0.5117145208089732, 130, 86, 128, 93]\n",
      "\n",
      "Validation: 0.5364535966393833\n",
      "min_df: 65\n",
      "alpha: 0.33\n",
      "[0.5086938634099866, 127, 85, 131, 94]\n",
      "\n",
      "Validation: 0.5345156121432593\n",
      "min_df: 66\n",
      "alpha: 0.0\n",
      "[0.5086938634099866, 127, 85, 131, 94]\n",
      "\n",
      "Validation: 0.5345156121432593\n",
      "min_df: 67\n",
      "alpha: 0.45\n",
      "[0.5059005673206011, 127, 86, 131, 93]\n",
      "\n",
      "Validation: 0.5325776276471352\n",
      "min_df: 68\n",
      "alpha: 0.48\n",
      "[0.503962582824477, 126, 86, 132, 93]\n",
      "\n",
      "Validation: 0.5250530509722403\n",
      "min_df: 69\n",
      "alpha: 0.48\n",
      "[0.5059005673206011, 127, 86, 131, 93]\n",
      "\n",
      "Validation: 0.5342882508336582\n",
      "min_df: 70\n",
      "alpha: 0.81\n",
      "[0.5114871594993721, 127, 84, 131, 95]\n",
      "\n",
      "Validation: 0.5267636741587631\n",
      "min_df: 71\n",
      "alpha: 0.26\n",
      "[0.5114871594993721, 127, 84, 131, 95]\n",
      "\n",
      "Validation: 0.5200944090771296\n",
      "min_df: 72\n",
      "alpha: 0.79\n",
      "[0.5134251439954961, 128, 84, 130, 95]\n",
      "\n",
      "Validation: 0.5117145208089732\n",
      "min_df: 73\n",
      "alpha: 0.0\n",
      "[0.5153631284916201, 129, 84, 129, 95]\n",
      "\n",
      "Validation: 0.5155904898012212\n",
      "min_df: 74\n",
      "alpha: 0.11\n",
      "[0.5125698324022346, 129, 85, 129, 94]\n",
      "\n",
      "Validation: 0.5231150664761163\n",
      "min_df: 75\n",
      "alpha: 0.65\n",
      "[0.5142804555887575, 127, 83, 131, 96]\n",
      "\n",
      "Validation: 0.5203217703867308\n",
      "min_df: 76\n",
      "alpha: 0.0\n",
      "[0.5142804555887575, 127, 83, 131, 96]\n",
      "\n",
      "Validation: 0.5203217703867308\n",
      "min_df: 77\n",
      "alpha: 0.0\n",
      "[0.5162184400848815, 128, 83, 130, 96]\n",
      "\n",
      "Validation: 0.5086938634099866\n",
      "min_df: 78\n",
      "alpha: 0.71\n",
      "[0.5162184400848815, 128, 83, 130, 96]\n",
      "\n",
      "Validation: 0.5173011129877442\n",
      "min_df: 79\n",
      "alpha: 0.51\n",
      "[0.5181564245810055, 129, 83, 129, 96]\n",
      "\n",
      "Validation: 0.5181564245810055\n",
      "min_df: 80\n",
      "alpha: 0.8\n",
      "[0.5134251439954961, 128, 84, 130, 95]\n",
      "\n",
      "Validation: 0.5078385518167251\n",
      "min_df: 81\n",
      "alpha: 0.0\n",
      "[0.5200944090771296, 130, 83, 128, 96]\n",
      "\n",
      "Validation: 0.5117145208089732\n",
      "min_df: 82\n",
      "alpha: 0.13\n",
      "[0.5153631284916201, 129, 84, 129, 95]\n",
      "\n",
      "Validation: 0.5153631284916201\n",
      "min_df: 83\n",
      "alpha: 0.92\n",
      "[0.5022519596379542, 128, 88, 130, 91]\n",
      "\n",
      "Validation: 0.5342882508336582\n",
      "min_df: 84\n",
      "alpha: 0.9\n",
      "[0.5041899441340782, 129, 88, 129, 91]\n",
      "\n",
      "Validation: 0.5314949547442727\n",
      "min_df: 85\n",
      "alpha: 0.51\n",
      "[0.5069832402234637, 129, 87, 129, 92]\n",
      "\n",
      "Validation: 0.5220323935732536\n",
      "min_df: 86\n",
      "alpha: 0.42\n",
      "[0.5050452557273397, 128, 87, 130, 92]\n",
      "\n",
      "Validation: 0.5239703780693776\n",
      "min_df: 87\n",
      "alpha: 0.09\n",
      "[0.49558269455632065, 126, 89, 132, 90]\n",
      "\n",
      "Validation: 0.5250530509722403\n",
      "min_df: 88\n",
      "alpha: 0.0\n",
      "[0.49860335195530725, 129, 90, 129, 89]\n",
      "\n",
      "Validation: 0.5222597548828548\n",
      "min_df: 89\n",
      "alpha: 0.56\n",
      "[0.4994586635485687, 128, 89, 130, 90]\n",
      "\n",
      "Validation: 0.5287016586548872\n",
      "min_df: 90\n",
      "alpha: 0.0\n",
      "[0.5061279286302023, 130, 88, 128, 91]\n",
      "\n",
      "Validation: 0.5231150664761163\n",
      "min_df: 91\n",
      "alpha: 0.87\n",
      "[0.5061279286302023, 130, 88, 128, 91]\n",
      "\n",
      "Validation: 0.5278463470616257\n",
      "min_df: 92\n",
      "alpha: 0.6\n",
      "[0.5080659131263263, 131, 88, 127, 91]\n",
      "\n",
      "Validation: 0.5373089082326448\n",
      "min_df: 93\n",
      "alpha: 0.5\n",
      "[0.5052726170369408, 131, 89, 127, 90]\n",
      "\n",
      "Validation: 0.5381642198259062\n",
      "min_df: 94\n",
      "alpha: 0.03\n",
      "[0.5063552899398034, 133, 90, 125, 89]\n",
      "\n",
      "Validation: 0.5306396431510112\n",
      "min_df: 95\n",
      "alpha: 0.55\n",
      "[0.5110865705253129, 134, 89, 124, 90]\n",
      "\n",
      "Validation: 0.5353709237365207\n",
      "min_df: 96\n",
      "alpha: 0.67\n",
      "[0.5127971937118359, 132, 87, 126, 92]\n",
      "\n",
      "Validation: 0.5362262353297822\n",
      "min_df: 97\n",
      "alpha: 0.79\n",
      "[0.5100038976224504, 132, 88, 126, 91]\n",
      "\n",
      "Validation: 0.5314949547442727\n",
      "min_df: 98\n",
      "alpha: 0.0\n",
      "[0.5119418821185744, 133, 88, 125, 91]\n",
      "\n",
      "Validation: 0.5278463470616257\n",
      "min_df: 99\n",
      "alpha: 0.79\n",
      "[0.5044173054436794, 132, 90, 126, 89]\n",
      "\n",
      "Validation: 0.5306396431510112\n",
      "min_df: 100\n",
      "alpha: 0.16\n",
      "[0.5016240093542939, 132, 91, 126, 88]\n",
      "\n",
      "Validation: 0.5325776276471352\n",
      "min_df: 101\n",
      "alpha: 0.0\n",
      "[0.5016240093542939, 132, 91, 126, 88]\n",
      "\n",
      "Validation: 0.5306396431510112\n",
      "min_df: 102\n",
      "alpha: 0.0\n",
      "[0.4996860248581698, 131, 91, 127, 88]\n",
      "\n",
      "Validation: 0.5373089082326448\n",
      "min_df: 103\n",
      "alpha: 0.0\n",
      "[0.4988307132649084, 132, 92, 126, 87]\n",
      "\n",
      "Validation: 0.5411848772248928\n",
      "min_df: 104\n",
      "alpha: 0.0\n",
      "[0.4996860248581698, 131, 91, 127, 88]\n",
      "\n",
      "Validation: 0.5308670044606124\n",
      "min_df: 105\n",
      "alpha: 0.0\n",
      "[0.497975401671647, 133, 93, 125, 86]\n",
      "\n",
      "Validation: 0.5308670044606124\n",
      "min_df: 106\n",
      "alpha: 0.0\n",
      "[0.4988307132649084, 132, 92, 126, 87]\n",
      "\n",
      "Validation: 0.5280737083712269\n",
      "min_df: 107\n",
      "alpha: 0.0\n",
      "[0.5007686977610324, 133, 92, 125, 87]\n",
      "\n",
      "Validation: 0.5336603005499978\n",
      "min_df: 108\n",
      "alpha: 0.0\n",
      "[0.5035619938504179, 133, 91, 125, 88]\n",
      "\n",
      "Validation: 0.5375362695422459\n",
      "min_df: 109\n",
      "alpha: 0.47000000000000003\n",
      "[0.5007686977610324, 133, 92, 125, 87]\n",
      "\n",
      "Validation: 0.5355982850461218\n",
      "min_df: 110\n",
      "alpha: 0.76\n",
      "[0.5035619938504179, 133, 91, 125, 88]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 0.5355982850461218\n",
      "min_df: 111\n",
      "alpha: 0.96\n",
      "[0.5091485860291889, 133, 89, 125, 90]\n",
      "\n",
      "Validation: 0.5308670044606124\n",
      "min_df: 112\n",
      "alpha: 0.6900000000000001\n",
      "[0.5121692434281755, 136, 90, 122, 89]\n",
      "\n",
      "Validation: 0.5355982850461218\n",
      "min_df: 113\n",
      "alpha: 0.48\n",
      "[0.511313931834914, 137, 91, 121, 88]\n",
      "\n",
      "Validation: 0.5355982850461218\n",
      "min_df: 114\n",
      "alpha: 0.0\n",
      "[0.5082932744359274, 134, 90, 124, 89]\n",
      "\n",
      "Validation: 0.5252804122818414\n",
      "min_df: 115\n",
      "alpha: 0.0\n",
      "[0.5063552899398034, 133, 90, 125, 89]\n",
      "\n",
      "Validation: 0.5252804122818414\n",
      "min_df: 116\n",
      "alpha: 0.0\n",
      "[0.4996860248581698, 131, 91, 127, 88]\n",
      "\n",
      "Validation: 0.5328049889567363\n",
      "min_df: 117\n",
      "alpha: 0.0\n",
      "[0.4996860248581698, 131, 91, 127, 88]\n",
      "\n",
      "Validation: 0.5310943657702134\n",
      "min_df: 118\n",
      "alpha: 0.0\n",
      "[0.5027066822571564, 134, 92, 124, 87]\n",
      "\n",
      "Validation: 0.5319496773634749\n",
      "min_df: 119\n",
      "alpha: 0.0\n",
      "[0.507437962842666, 135, 91, 123, 88]\n",
      "\n",
      "Validation: 0.5338876618595989\n",
      "min_df: 120\n",
      "alpha: 0.0\n",
      "[0.497975401671647, 133, 93, 125, 86]\n",
      "\n",
      "Validation: 0.5422675501277554\n",
      "min_df: 121\n",
      "alpha: 0.35000000000000003\n",
      "[0.4968927287687844, 131, 92, 127, 87]\n",
      "\n",
      "Validation: 0.5405569269412325\n",
      "min_df: 122\n",
      "alpha: 0.0\n",
      "[0.4996860248581698, 131, 91, 127, 88]\n",
      "\n",
      "Validation: 0.5310943657702134\n",
      "min_df: 123\n",
      "alpha: 0.96\n",
      "[0.5054999783465419, 134, 91, 124, 88]\n",
      "\n",
      "Validation: 0.530239054176952\n",
      "min_df: 124\n",
      "alpha: 0.0\n",
      "[0.5016240093542939, 132, 91, 126, 88]\n",
      "\n",
      "Validation: 0.5235697890953185\n",
      "min_df: 125\n",
      "alpha: 0.0\n",
      "[0.5007686977610324, 133, 92, 125, 87]\n",
      "\n",
      "Validation: 0.5207764930059331\n",
      "min_df: 126\n",
      "alpha: 0.0\n",
      "[0.4996860248581698, 131, 91, 127, 88]\n",
      "\n",
      "Validation: 0.528301069680828\n",
      "min_df: 127\n",
      "alpha: 0.12\n",
      "[0.4996860248581698, 131, 91, 127, 88]\n",
      "\n",
      "Validation: 0.526363085184704\n",
      "min_df: 128\n",
      "alpha: 0.0\n",
      "[0.5005413364514313, 130, 90, 128, 89]\n",
      "\n",
      "Validation: 0.5285284309904292\n",
      "min_df: 129\n",
      "alpha: 0.0\n",
      "[0.5024793209475553, 131, 90, 127, 89]\n",
      "\n",
      "Validation: 0.5218591659087957\n",
      "min_df: 130\n",
      "alpha: 0.0\n",
      "[0.4977480403620458, 130, 91, 128, 88]\n",
      "\n",
      "[[0.5422675501277554, 121, 0.35000000000000003]]\n"
     ]
    }
   ],
   "source": [
    "def naive_bayes_tuning(df):\n",
    "    all_results = []\n",
    "    \n",
    "    for min_df in range(24, 131):\n",
    "        tokenizer = CountVectorizer(analyzer=\"word\", lowercase=False, min_df=min_df, ngram_range=(1, 1))\n",
    "        tokenized_words = tokenizer.fit_transform(df[\"combined\"])\n",
    "\n",
    "        # training, validation, testing\n",
    "        X_train, X_test, y_train, y_test = train_test_split(tokenized_words, df[\"label\"], test_size=0.2,shuffle=True, random_state=42)\n",
    "        X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, shuffle=True, random_state=42)\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for alpha in range(101): \n",
    "            alpha *= 0.01\n",
    "            model = MultinomialNB(alpha=alpha, fit_prior=True)\n",
    "            model.fit(X_train, y_train)\n",
    "            predict = model.predict(X_val)\n",
    "\n",
    "            conf = pd.DataFrame({\"Predicted\": predict, \"Actual\":y_val})\n",
    "            balance = my_confusion_matrix(conf, \"Predicted\", \"Actual\", up=1, down=0)[0]\n",
    "            results.append([balance, alpha])\n",
    "\n",
    "\n",
    "        best_result = max(results, key=lambda sublist: sublist[0])\n",
    "\n",
    "        model = MultinomialNB(alpha=best_result[1], fit_prior=True)\n",
    "        model.fit(X_train, y_train)\n",
    "        predict = model.predict(X_test)\n",
    "        conf = pd.DataFrame({\"Predicted\": predict, \"Actual\":y_val})\n",
    "        print(\"Validation:\", best_result[0])\n",
    "        print(\"min_df:\", min_df)\n",
    "        print(\"alpha:\", best_result[1])\n",
    "        print(my_confusion_matrix(conf, \"Predicted\", \"Actual\", up=1, down=0))\n",
    "        print()\n",
    "        \n",
    "        all_results.append([best_result[0], min_df, best_result[1]])\n",
    "        \n",
    "    return all_results\n",
    "\n",
    "all_results = naive_bayes_tuning(df)\n",
    "\n",
    "# Find the maximum element in the first column\n",
    "max_value = max(row[0] for row in all_results)\n",
    "\n",
    "# Find the subarray(s) with the maximum element in the first column\n",
    "max_subarrays = [row for row in all_results if row[0] == max_value]\n",
    "\n",
    "print(max_subarrays) # [[0.5422675501277554, 121, 0.35000000000000003]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b52c15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1591,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "/Users/filipneubauer/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 27\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     31\u001b[0m fitting_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/bayes/.venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/bayes/.venv/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/Desktop/bayes/.venv/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/Desktop/bayes/.venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:440\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"combined\"], df[\"label\"], test_size=0.2,shuffle=True, random_state=42)\n",
    "print(X_train.shape)\n",
    "\n",
    "tokenizer = CountVectorizer(analyzer=\"word\", lowercase=False, ngram_range=(1,1))\n",
    "#tokenized_words = tokenizer.fit_transform(X_train[\"combined\"])\n",
    "\n",
    "\n",
    "estimator = MultinomialNB()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"tokenizer\", tokenizer),\n",
    "    (\"estimator\", estimator)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"tokenizer__min_df\": [i for i in range(20, 125)],\n",
    "    #\"custom__min_df\": [i for i in range(10)],\n",
    "    \"estimator__alpha\": [i * 0.1 for i in range(10)],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, scoring=\"balanced_accuracy\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "fitting_time = end_time - start_time\n",
    "\n",
    "print(fitting_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58308c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator__alpha': 0.8, 'tokenizer__min_df': 23}\n",
      "[0.5084499059690342, 118, 86, 109, 85]\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "predict = best_model.predict(X_test)\n",
    "conf = pd.DataFrame({\"Predicted\": predict, \"Actual\":y_test})\n",
    "print(my_confusion_matrix(conf, \"Predicted\", \"Actual\", up=1, down=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "403d5265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = grid_search.cv_results_\n",
    "\n",
    "#print(results)\n",
    "\n",
    "param_grid_keys = list(param_grid.keys())\n",
    "param_values = [results[f'param_{key}'] for key in param_grid_keys]\n",
    "\n",
    "mean_test_scores = results['mean_test_score']\n",
    "results_df = pd.DataFrame({'alpha': param_values[0], 'min_df': param_values[1], 'Mean_Test_Score': mean_test_scores})\n",
    "\n",
    "heatmap_data = results_df.pivot(index='min_df', columns='alpha', values='Mean_Test_Score')\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(heatmap_data, annot=False, cmap='viridis', fmt='.3f', cbar=True)\n",
    "plt.title('Grid Search Training Heatmap Naive Bayes')\n",
    "plt.xlabel('min_df')\n",
    "plt.ylabel('alpha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a352c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
