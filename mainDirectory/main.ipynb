{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c7f59d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import inflect\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "933379bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "\n",
    "# modified stop words so that they are without punctuation\n",
    "def create_my_stop_words():\n",
    "    my_stop_words = []       # stop words without punctuation\n",
    "    for word in stopwords.words(\"english\"): \n",
    "        my_word = \"\"\n",
    "        for char in word:\n",
    "            if char not in string.punctuation:\n",
    "                my_word += char\n",
    "        my_stop_words.append(my_word)\n",
    "\n",
    "    other_not_included = [\"hed\", \"itd\", \"theyd\", \"youd\", \"me\"] # shed, wed, id are common words but he had, it had, they had, you had\n",
    "    for word in other_not_included:\n",
    "        my_stop_words.append(word)\n",
    "    return my_stop_words\n",
    "\n",
    "\n",
    "# plural word -> singular word\n",
    "def singularize_word(word):\n",
    "    p = inflect.engine()\n",
    "    singular_word = p.singular_noun(word)\n",
    "    if singular_word:\n",
    "        return singular_word\n",
    "    else:\n",
    "        return word\n",
    "    \n",
    "\n",
    "# prepare dataset\n",
    "def prepare_kaggle_dataset(df):\n",
    "    df.fillna(\"\", inplace=True) # filling empty fields\n",
    "    df[\"combined\"] = df[['Top1', \"Top2\", \"Top3\", 'Top4', 'Top5', 'Top6', 'Top7',\n",
    "      'Top8', 'Top9', 'Top10', 'Top11', 'Top12', 'Top13', 'Top14', 'Top15',\n",
    "      'Top16', 'Top17', 'Top18', 'Top19', 'Top20', 'Top21', 'Top22', 'Top23',\n",
    "       'Top24', 'Top25']].apply(lambda row: \" \".join(row), axis=1) # combining all columns into one\n",
    "    \n",
    "    new_df = pd.DataFrame(data={\"combined\": df[\"combined\"], \"label\": df[\"Label\"]})\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "\n",
    "#test = 0\n",
    "\n",
    "# text cleaning \n",
    "def text_cleanning(row):\n",
    "    global test\n",
    "    remove_b = row.replace(\"b\\\"\", \"\").replace(\"b'\", \"\")   # removing b\" and b'\n",
    "    remove_punc = \"\".join([char for char in remove_b if char not in string.punctuation])     # removing punctuation !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
    "    remove_stop_words = [word for word in remove_punc.split() if word.lower() not in my_stop_words]  # removing stopwords\n",
    "    \n",
    "\n",
    "\n",
    "    # comparing different techniques for removing suffixis\n",
    "    \"\"\"\n",
    "    for i in remove_stop_words:\n",
    "        print(i, \" : \", porter_stemmer.stem(i, to_lowercase=False), \" : \", lemmatizer.lemmatize(i), \" : \", singularize_word(i))\n",
    "    \"\"\"\n",
    "    \n",
    "    lem_words = [lemmatizer.lemmatize(word) for word in remove_stop_words] # base of the words\n",
    "\n",
    "    singular_words = [singularize_word(word) for word in lem_words]         # plural -> singular\n",
    "    #if \"me\" in singular_words or \"Me\" in singular_words:\n",
    "     #   test += 1\n",
    "\n",
    "    return \" \".join(singular_words)  # returning cleaned row as a string\n",
    "\n",
    "\n",
    "# get each word in Count Vectorizer with its count in 0, 1 and total\n",
    "def get_word_counts():\n",
    "    feature_names = cv.get_feature_names_out()\n",
    "\n",
    "    # Get the indices of the \"0\" and \"1\" texts in the DataFrame\n",
    "    indices_0 = df[df[\"label\"] == 0].index\n",
    "    indices_1 = df[df[\"label\"] == 1].index\n",
    "\n",
    "    # Get the occurrences of each word in the \"0\" texts\n",
    "    word_counts_0 = tokenized_words[indices_0].sum(axis=0)\n",
    "\n",
    "    # Get the occurrences of each word in the \"1\" texts\n",
    "    word_counts_1 = tokenized_words[indices_1].sum(axis=0)\n",
    "\n",
    "    # Create a dictionary to store the word counts\n",
    "    word_counts = {\n",
    "        \"word\": feature_names,\n",
    "        \"count_0\": word_counts_0.tolist()[0],\n",
    "        \"count_1\": word_counts_1.tolist()[0],\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Create a DataFrame from the word counts dictionary\n",
    "    word_counts_df = pd.DataFrame(word_counts)\n",
    "    word_counts_df[\"count\"] = word_counts_df[\"count_0\"] + word_counts_df[\"count_1\"]\n",
    "\n",
    "    return word_counts_df\n",
    "\n",
    "\n",
    "# printing the prob table\n",
    "def print_probabilities():\n",
    "    feature_log_probs = model.feature_log_prob_\n",
    "\n",
    "    # Convert feature log probabilities to probabilities\n",
    "    feature_probs = np.exp(feature_log_probs)\n",
    "\n",
    "    sorted_vocabulary = sorted(cv.vocabulary_.items(), key=lambda x: x[1])\n",
    "\n",
    "    vocab_arr = [item[0] for item in sorted_vocabulary]\n",
    "\n",
    "    # Create a DataFrame to represent the probabilistic table\n",
    "    prob_table = pd.DataFrame(feature_probs, columns=vocab_arr)\n",
    "\n",
    "    word_counts_df = get_word_counts()  # getting the counts\n",
    "    word_counts_df.set_index(\"word\", inplace=True)  # making the word column index so it will match the prob_table\n",
    "    \n",
    "    prob_table = prob_table.transpose().sort_index()\n",
    "    prob_table[\"count\"] = word_counts_df[\"count\"]\n",
    "    prob_table[\"count_0\"] = word_counts_df[\"count_0\"]\n",
    "    prob_table[\"count_1\"] = word_counts_df[\"count_1\"]\n",
    "    \n",
    "    \n",
    "    for_csv = prob_table.reset_index()   # adding indexes back\n",
    "    for_csv.to_csv(\"words_for_analysis.csv\")\n",
    "    \n",
    "    # probability ratio\n",
    "    prob_table[\"prob_ratio\"] =  prob_table.iloc[:,1] / prob_table.iloc[:, 0]\n",
    "    \n",
    "    # product of prob_ratio and count\n",
    "    prob_table[\"product_ratio_count\"] = prob_table[\"count\"] * prob_table[\"prob_ratio\"]\n",
    "\n",
    "    # priting the dataframe to a txt file\n",
    "    with open(\"output.txt\", \"w\") as f:\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.width', None)\n",
    "        pd.set_option('display.expand_frame_repr', False)\n",
    "        #pd.set_option('display.max_colwidth', -1) \n",
    "\n",
    "        #print(prob_table.sort_values(\"pomer\",  ascending=False), file=f) # sort by biggest impact on 0\n",
    "        print(prob_table.sort_values(\"product_ratio_count\", ascending=False), file=f)\n",
    "        \n",
    "\n",
    "        pd.reset_option('all')\n",
    "        \n",
    "\n",
    "# checking the performance\n",
    "def my_confusion_matrix(data, predicted_col, true_col, up=\"up\", down=\"down\"):\n",
    "    tp = data.loc[(data[predicted_col] == up) & (data[true_col] == up)]\n",
    "    fp = data.loc[(data[predicted_col] == up) & (data[true_col] == down)]\n",
    "    fn = data.loc[(data[predicted_col] == down) & (data[true_col] == up)]\n",
    "    tn = data.loc[(data[predicted_col] == down) & (data[true_col] == down)]\n",
    "\n",
    "    df = pd.DataFrame({\"Actual up\":[len(tp), len(fn)], \"Actual Down\":[len(fp), len(tn)]}, index=[\"Predicted up\", \"Predicted down\"])\n",
    "\n",
    "    performance = (len(tp) + len(tn)) / (len(tp) + len(tn) + len(fp) + len(fn))\n",
    "    accuracyP = (len(tp) / (len(tp) + len(fp)))\n",
    "\n",
    "    if (len(tn) + len(fn)) == 0:\n",
    "        accuracyN = \"no negatives predicted\"\n",
    "    else:\n",
    "        accuracyN = (len(tn) / (len(tn) + len(fn)))\n",
    "\n",
    "\n",
    "    print(df)\n",
    "    print(\"Performance: \", performance)\n",
    "    print(\"Accuracy Positives: \", accuracyP)\n",
    "    print(\"Accuracy Negatives: \", accuracyN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "277d11d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create necessary instances\n",
    "\n",
    "\n",
    "# tokenizer\n",
    "cv = CountVectorizer(analyzer=\"word\", lowercase=False, min_df=3) # ngram_range=(2,2)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "my_stop_words = create_my_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "230b5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load kaggle data\n",
    "df = pd.read_csv(\"Combined_News_DJIA.csv\")\n",
    "df = prepare_kaggle_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "02563808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load news category data\n",
    "df_2 = pd.read_csv(\"news_category_data.csv\")\n",
    "\n",
    "# concatenate\n",
    "df = pd.concat([df, df_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "906a03f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean each row + asigning numbers to words\n",
    "df[\"combined\"] = df['combined'].apply(text_cleanning)\n",
    "#print(test)\n",
    "tokenized_words = cv.fit_transform(df[\"combined\"])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "14e5b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting data into training and testing date sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tokenized_words, df[\"label\"], test_size=0.1, shuffle=True, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4e2e20ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Actual up  Actual Down\n",
      "Predicted up          130          105\n",
      "Predicted down        120           82\n",
      "Performance:  0.4851258581235698\n",
      "Accuracy Positives:  0.5531914893617021\n",
      "Accuracy Negatives:  0.40594059405940597\n"
     ]
    }
   ],
   "source": [
    "# creating the model and fitting the data\n",
    "model = MultinomialNB(alpha=0.1, fit_prior=False)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# making predictions for testing\n",
    "predict = model.predict(X_test)\n",
    "\n",
    "# printing the confusion matrix\n",
    "conf = pd.DataFrame({\"Predicted\": predict, \"Actual\":y_test})\n",
    "my_confusion_matrix(conf, \"Predicted\", \"Actual\", up=1, down=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3e207964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1_/_85l6zx17ybc3xvtmwp5p49c0000gn/T/ipykernel_3285/2382375518.py:142: FutureWarning: column_space is deprecated and will be removed in a future version. Use df.to_string(col_space=...) instead.\n",
      "  pd.reset_option('all')\n",
      "/var/folders/1_/_85l6zx17ybc3xvtmwp5p49c0000gn/T/ipykernel_3285/2382375518.py:142: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead.\n",
      "  pd.reset_option('all')\n",
      "/var/folders/1_/_85l6zx17ybc3xvtmwp5p49c0000gn/T/ipykernel_3285/2382375518.py:142: FutureWarning: \n",
      ": boolean\n",
      "    use_inf_as_null had been deprecated and will be removed in a future\n",
      "    version. Use `use_inf_as_na` instead.\n",
      "\n",
      "  pd.reset_option('all')\n"
     ]
    }
   ],
   "source": [
    "# print the probabilities to output.txt\n",
    "print_probabilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e819875f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ed9ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f82d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc02de63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac658ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4054cdab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae25696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b84afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd9876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
